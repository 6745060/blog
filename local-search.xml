<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Critique: Why GPUs are slow at executing NFAs and how to make them faster.</title>
    <link href="/2021/01/20/Reading-Why-GPUs-are-slow-at-executing-NFAs-and-how-to-make-them-faster/"/>
    <url>/2021/01/20/Reading-Why-GPUs-are-slow-at-executing-NFAs-and-how-to-make-them-faster/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>Paper</strong>: Liu, Hongyuan, Sreepathi Pai, and Adwait Jog. “Why GPUs are slow at executing NFAs and how to make them faster.” Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. 2020.</p></blockquote><p><a href="https://dl.acm.org/doi/abs/10.1145/3373376.3378471">Paper PDF</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This paper introduces a new dynamic scheme that effectively balances compute utilization with reduced memory usage for GPUs when executing NFAs. Specifically, the authors identify two performance bottlenecks in the NFA matching process, one is the excessive data movement, the other is poor compute utilization. To tackle these problems, three proposals are demonstrated including 1) using on-chip resources when possible, 2) converting memory accesses to compute 3) mapping only active states to threads. Overall, this study achieves better performance compared with the previous state-of-art GPU implementations of NFAs across a wide range of emerging applications.</p><p>In general, this paper focuses on solving a challenge domain-specific problem in the area of GPU. I hold a positive view of the sophisticated scheme and well-designed experiments in this paper for the reason that the methodology and experiments of the article utilize the characteristics of NFA and GPU, and the latter gives sufficient evidence to support these methods. Moreover, to the best of my knowledge, in the context of NFA processing, no prior work has considered both data movement and utilization problems in conjunction. However, it should be noted that there are some trivial flaws in the choice of the comparison method and the organization of the paper is not satisfactory.</p><p><img src="https://gitee.com/omegaxyz/img/raw/master/upload/GPU_NFA202101201211.jpg" alt=""></p><p>In the following parts, I will analyze the whole paper in detail in terms of writing skills, method design, and experiment, etc.</p><h2 id="Strengths"><a href="#Strengths" class="headerlink" title="Strengths"></a>Strengths</h2><p>The strengths of the paper have several aspects. First of all, unlike most papers, the title of this paper asked two questions directly which gives an outlook for readers to preview the context of the article directly.</p><p>From a high perspective, I think the proposed new data structure to store NFA pattern in this paper is sophisticated and utilize the characteristics of GPU execution since it is challenging for GPUs to obtain enough threads for assigning node data structure which utilizes a 256-bit array of match set, 4 outgoing edges in a 64-bit integer, and an 8-bit array of attributes (3 bits are used to record start state, accept state and always-active state; other 2bits are used for compression). The authors examine the behavior of states and determine which states have high activity frequency and which states have low activity frequency. For example, one of the schemes uses the 1KB prefix of the 1MB input as the profiling input. If a state has an activation frequency more than a threshold in the profiling input, the process considers it as a hot state during the entire execution.</p><p>In addition, I think the new data structure can save many redundant spaces which is be of some use for future GPU optimization. In the structure, each node consumes 41 bytes leading to 41N bytes in total compared to 4096N bytes for the alphabet-oriented transition table. Apparently, the scheme only uses 1% space of the traditional table which enables the execution to better exploit the on-chip resources of GPU for topology and the match sets of NFAs.</p><p>In terms of the proposed compressing match set, it is intuitively feasible to reduce the number of checking the array of trigger symbols. Specifically, the compressing match set will be marked by the first element and the last element when the arrays have special attributes such as containing a continuous set of bit 1s or a continuous set of bit 0s. When a thread examines a matching set that has that attribute, it can examine in that range instead of checking all the bits. Based on that behavior, high-frequency states will be mapped one-one to threads while the low-frequency states will be stored in a list, and a thread takes responsibility for one or many elements in the list which depends on the available computational resource. Besides, from the beginning to the end of the article, it illustrates the complicated process above by using a simple but comprehensive NFA example that only contains 4 different states. Thus, it is easy for us to understanding and analyzing the whole story to some extent.</p><p>Next, as far as I’m concerned, one of the biggest advantages of this paper is that the experiments are detailed and well designed. On one hand, the experiments have designed several evaluation methods which are complete and standardized. These methods contain the characteristics of evaluated NFA applications, throughput enhancement results, absolute throughput with the proposed schemes, effect on data movement reduction, and performance sensitivity to Volta GPU architecture. In particular, all the experimental data gives a convincing analysis. On the other hand, in the appendix of the paper, the authors provide the artifact where there are source code, datasets, workflow, and dependencies, etc. All of them further prove the correctness of the experiment which can provide much convenience for future researchers eventually.</p><p>Considering the result of the performance sensitivity to Volta GPU architecture, the proposed schemes (HotStart-MaC and HotStart) show more than 15× speedup over iNFAnt[1], indicating their effectiveness on newer GPU architectures which is a great improvement compared to other methods.</p><p>Last but not least, another strength of the article is the proposed method doesn’t contain additional hardware (i.e. hardware-free) to improve the performance of computing NFA-based applications which greatly reduces the cost of deployment and maintenance. Advanced users can easily use the given scheme with the artifact to optimize a specific program.</p><h2 id="Weaknesses"><a href="#Weaknesses" class="headerlink" title="Weaknesses"></a>Weaknesses</h2><p>When talking about the weakness, the organization or structure of the article should be mentioned first inevitably. The paper including several sections, they are Introduction, background, problem/previous efforts, addressing the data movement problem via match set analysis, addressing the utilization problem via activity analysis, evaluation methodology, experimental results, related work, and conclusions. Obviously, there is redundancy between the chapters which will confuse readers to a certain degree. Sections like background, problem, and previous efforts, and related work can be merged together which provides the preliminaries to the proposed methods. Moreover, the experiments should become an independent chapter including addressing the proposed methods, evaluation methodology, and experimental results rather than splitting them into several independent sections.</p><p>Although the experiment is very well designed, its comparison algorithm is old in section 6. For example, iNFAnt[1] and NFA-CG[2] were proposed almost ten years ago which makes the contributions downgraded and unconvincing. Therefore, from my perspective, the paper is supposed to find more comparison methods that maybe not necessarily the application to NFAs to show the advancement of the proposed GPU schemes.</p><p>Also, in the experimental part, I find that the effect on data movement reduction isn’t improved a lot, though the utilization optimization reduces the number of thread blocks that access the transition table and the input streams. It can be observed that HotStart (section 5), HotStart-MAC (section 5), NT (section 4.2), and NT-MAC (section 4.3) use 98.9%, 99.3%, 95.9%, and 96.1% gld_transactions respectively while NFA-CG uses 88.2% gld_transactions where the first four names are proposed schemes. One of the possible reasons is that many current methods have improved the data movement reduction to the limitation which is hard to make a great move. Thus, it can be concluded that the data movement reduction is the necessary optimization aspect for NFAs execution. Here, many researchers may consider whether there are more directions for optimization[3] in technique rather than simply reducing data movement.</p><p>Furthermore, as a domain-specific paper, the related work (section 8) only demonstrates the work on reducing data movement and improving utilization used in the main process of the newly proposed method. It would be better if the related work could introduce more up-to-date specific methods or GPU accelerators so that readers will have a better understanding of the bottlenecks to improve the throughput of the NFA matching process using GPUs.</p><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>As  I have said above, the proposed scheme is hardware-free but if we take the throughput into consideration again, we can infer that the performance could be better with the help of hardware/software co-design optimizations to close the remaining gap between hardware and software.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Generally, the work has more strengths than weaknesses. Strengths include the sophisticated data structure and detailed experiments while there are some flaws in the organization of the article and out-of-date comparison methods. In summary, this paper gives a novel way to optimize NFA execution in GPU from the perspective of the software and can guide future work to optimize GPGPU in the aspect of data movement and structure compression.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Cascarano, Niccolo, et al. “iNFAnt: NFA pattern matching on GPGPU devices.” ACM SIGCOMM Computer Communication Review 40.5 (2010): 20-26.<br>[2] Zu, Yuan, et al. “GPU-based NFA implementation for memory efficient high speed regular expression matching.” Proceedings of the 17th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming. 2012.<br>[3] Vu, Kien Chi. “Accelerating bit-based finite automaton on a GPGPU device.” (2020).</p><blockquote><p><a href="https://www.omegaxyz.com/2020/12/31/nfa_gpu/">Original</a> </p></blockquote>]]></content>
    
    
    <categories>
      
      <category>technology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>computer architecture</tag>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Defend the truth: seeing is not believing anymore</title>
    <link href="/2021/01/20/Defend-the-truth-seeing-is-not-believing-anymore/"/>
    <url>/2021/01/20/Defend-the-truth-seeing-is-not-believing-anymore/</url>
    
    <content type="html"><![CDATA[<h2 id="DeepFake"><a href="#DeepFake" class="headerlink" title="DeepFake"></a>DeepFake</h2><p>Imagine if someone replaces the character in a certain video with your face image just for fun, what would you think? This is what DeepFake is doing. Its function is to combine and superimpose existing videos onto source videos using generative adversarial network (GAN) [1]. The fusion of the existing and source videos outputs a fake video that shows a person acting at an event that never happened in reality.</p><p><img src="https://gitee.com/omegaxyz/img/raw/master/upload/deep-fake202101201024.jpg" alt=""></p><p>As we all know that every coin has two sides. On the good side, the technology in DeepFake provides more convenience for mankind to a certain degree. In the film industry, engineers are able to generate more exciting and incredible scenes while actors or actresses don’t really need to risk their lives. Moreover, DeepFake brings color to family parties or enhances friendship between companions if used properly. </p><p>There is no doubt that the development of technology especially artificial intelligence gives more power to common people. However, from my perspective, technology has no sense of morality nowadays because machine learning models have no consciousness. In other words, DeepFake executes instructions according to human wills which may result in more harm than good owing to people’s curiosity and selfishness. </p><p>As far as I am concerned, DeepFake has become a new tool threatening the era of social media. More unethical actions  could happen for the reason that most people tend to use this tool to prank on others or even forge a video that has never happened for a selfish goal maliciously. For example, the lives and portrait rights of many actresses have been threatened because someone replaced the faces of porn stars with many other face images which influenced public opinions and the careers of these actresses. Even more, what if we deepfake a video about Donald Trump during the presidential election in 2020? Not surprisingly, someone has already done this for the purpose to affect people’s tendency to vote. These are no longer moral issues, these behaviors have violated the law in many countries. </p><p>Under the current background of rapid economic and social development, whether it is about humanitarianism, product launches, or campaign activities, deepfaked videos and images may reverse black and white. Not only has the social order been challenged, but it is also difficult for us to see the truth in such a social situation. Seeing is not believing anymore.</p><p>It is time for us to defend the truth for a better tomorrow. Otherwise, with the advancement of science and technology, our society would fall into the brave new world as Huxley described [5]. In this world, our lives will be overwhelmed by a flood of irrelevant or fake information and even we will amuse ourselves to death [6]. In the next part, I will give some immature but feasible suggestions in the aspects of technology, law, etc. I hope they will be of some use.</p><p>Technically, researchers are supposed to design more powerful models to detect whether a video or an image is true or fake. Fortunately, there emerges some work for the detection of image or video forgeries such as [2], [3], and [4]. Besides, the legislature should introduce more stringent measures to prevent and stop these behaviors that disrupt social stability and order at the legal level. What needs to be pointed out is that the law punishes the people who abuse DeepFake, not the DeepFake inventors because the principle I have always believed is that technology is not guilty. Otherwise, it may hurt the development of science and technology which will result in the loss of vitality of technological creation.</p><p>Of course, social media like Twitter and Facebook should take more responsibility to detect and delete fake information and help create a harmonious and true community environment. Only in this way can media literacy be enhanced to cultivate a discerning public platform.</p><p>Last but not least, it should be realized that only truth leads to liberty, democracy, and human development. Therefore, to counter the menace of DeepFake, each of us needs to improve the ability to think independently and critically rather than spreads information as we like according to our tastes and interests. </p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Suwajanakorn, Supasorn, Steven M. Seitz, and Ira Kemelmacher-Shlizerman. “Synthesizing obama: learning lip sync from audio.” ACM Transactions on Graphics (TOG) 36.4 (2017): 1-13.<br>[2] Bappy, Jawadul H., et al. “Hybrid LSTM and encoder–decoder architecture for detection of image forgeries.” IEEE Transactions on Image Processing 28.7 (2019): 3286-3300.<br>[3] Tolosana, Ruben, et al. “Deepfakes and beyond: A survey of face manipulation and fake detection.” arXiv preprint arXiv:2001.00179 (2020).<br>[4] Güera, David, and Edward J. Delp. “Deepfake video detection using recurrent neural networks.” 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 2018.<br>[5] Huxley, Aldous. Brave new world. Ernst Klett Sprachen, 2007.<br>[6] Postman, Neil. Amusing ourselves to death: Public discourse in the age of show business. Penguin, 2006.</p>]]></content>
    
    
    <categories>
      
      <category>ideas</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ideas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/01/19/hello-world/"/>
    <url>/2021/01/19/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
